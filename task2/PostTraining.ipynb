{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5441f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f4ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric import\n",
    "\n",
    "# https://stackoverflow.com/questions/52041931/is-there-an-optimizer-in-keras-based-on-precision-or-recall-instead-of-loss\n",
    "from keras import backend as K\n",
    "THRESHOLD = 0.5\n",
    "def precision(y_true, y_pred, threshold_shift=0.5-THRESHOLD):\n",
    "\n",
    "    # just in case \n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred, threshold_shift=0.5-THRESHOLD):\n",
    "\n",
    "    # just in case \n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred_bin, 0, 1)))\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta(y_true, y_pred, beta = 2, threshold_shift=0.5-THRESHOLD):   \n",
    "    # just in case \n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d580303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Model\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "\n",
    "custom_metric = pickle.load(open(\"./model/bert_metric.pickle\", 'rb'))\n",
    "\n",
    "model = keras.models.load_model('./model/bertmodel', custom_objects=custom_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3090f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.predict of <keras.saving.saved_model.load.TFRobertaForSequenceClassification object at 0x0000019B221B9750>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a1961",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7bb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/full_covid.json\"\n",
    "ID_PATH = \"./data/covid.data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b8871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_replies_id_to_sorted_text(list_of_id, data_df):\n",
    "    \"\"\"Convert a list of tweet ids to a list of its corresponding text in data_df\n",
    "    Sort by tweets original create time\"\"\"\n",
    "    if type(list_of_id) is not list:\n",
    "        # if input is a single id convert type\n",
    "        list_of_id = [list_of_id]\n",
    "    # Select dataframe based on a list of ids\n",
    "    selected_df = data_df[data_df['id'].astype(str).isin(list_of_id)]\n",
    "    # Sort by their created time\n",
    "    sorted_df = selected_df.sort_values(by = [\"created_at\"])\n",
    "    # Select text fields only\n",
    "    text_list = sorted_df[\"text\"].to_list()\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def remove_URL(original):\n",
    "    \"\"\"Remove url link in the text\"\"\"\n",
    "    result = re.sub(r\"http\\S+\", \"\", original)\n",
    "    result = re.sub(r\"www.\\S+\", \"\", result)\n",
    "    result = re.sub(r\"wasap.my+\", \"\", result)\n",
    "    return result\n",
    "\n",
    "def join_data_id_label_v2(LABEL_PATH, ID_PATH, DATA_PATH):\n",
    "    # Process Labels\n",
    "    if LABEL_PATH:\n",
    "        # 1: Rumour\n",
    "        # 0: NonRumour\n",
    "        with open(LABEL_PATH, \"r\") as f:\n",
    "            y_label = f.read().strip().split(\"\\n\") # remove next line\n",
    "        y_label = pd.DataFrame(y_label, columns = [\"label\"])\n",
    "        y_label[y_label[\"label\"]==\"rumour\"] = 1\n",
    "        y_label[y_label[\"label\"]==\"nonrumour\"] = 0\n",
    "\n",
    "    ## Get Dataframe Id, with first id as source Id, and values as replies, not using dict since we have duplicated keys\n",
    "    total_id_list = []\n",
    "    with open(ID_PATH, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',') # remove next line\n",
    "            source_id = line[0]\n",
    "            if len(line) > 1:\n",
    "                # if we have replies id\n",
    "                replies_id = line[1:]\n",
    "            else:\n",
    "                replies_id = []\n",
    "            row = [source_id, replies_id]\n",
    "            total_id_list.append(row)\n",
    "    len(total_id_list)\n",
    "    \n",
    "    ## Create a dataframe containing a list of replies\n",
    "    source_df = pd.DataFrame(total_id_list, columns = ['source_id', 'replies_id'])\n",
    "    data_df = pd.read_json(DATA_PATH)\n",
    "    source_df[\"reply_text_list\"] = source_df[\"replies_id\"].apply(convert_replies_id_to_sorted_text, data_df = data_df)\n",
    "    source_df[\"source_text\"] = source_df[\"source_id\"].apply(convert_replies_id_to_sorted_text, data_df = data_df)\n",
    "\n",
    "    if LABEL_PATH:\n",
    "      source_df[\"label\"] = y_label\n",
    "    return source_df\n",
    "\n",
    "def bert_preprocess(IDS, DATA, LABELS=False):\n",
    "    \"\"\"Function to combine all the preprocessing steps\"\"\"\n",
    "    data = join_data_id_label_v2(LABELS, IDS, DATA)\n",
    "    ## 1. Only keep english tweets as most of them are in english\n",
    "    # Use only text data and remove URLs\n",
    "    #data[\"source\"] = data[\"source_text\"].apply(\" \".join).apply(p.clean) \n",
    "    #data[\"replies\"] = data[\"reply_text_list\"].apply(\" \".join).apply(p.clean)\n",
    "    data[\"source\"] = data[\"source_text\"].apply(\" \".join)\n",
    "    data[\"replies\"] = data[\"reply_text_list\"].apply(\" \".join)\n",
    "    \n",
    "    \n",
    "    if LABELS:\n",
    "      data = data[['source','replies','label']]\n",
    "    else:\n",
    "      data = data[['source','replies']]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = bert_preprocess(ID_PATH, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23befb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"./covid_bert_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87e0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
