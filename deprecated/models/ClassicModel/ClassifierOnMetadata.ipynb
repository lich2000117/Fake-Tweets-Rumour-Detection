{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6d3bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08e7ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_replies_id_to_sorted_text(list_of_id, data_df):\n",
    "    \"\"\"Convert a list of tweet ids to a list of its corresponding text in data_df\n",
    "    Sort by tweets original create time\"\"\"\n",
    "    if type(list_of_id) is not list:\n",
    "        # if input is a single id convert type\n",
    "        list_of_id = [list_of_id]\n",
    "    # Select dataframe based on a list of ids\n",
    "    selected_df = data_df[data_df['id'].astype(str).isin(list_of_id)]\n",
    "    # Sort by their created time\n",
    "    sorted_df = selected_df.sort_values(by = [\"created_at\"])\n",
    "    # Select text fields only\n",
    "    text_list = sorted_df[\"text\"].to_list()\n",
    "    return text_list\n",
    "\n",
    "def convert_replies_id_to_metrics(list_of_id, data_df):\n",
    "    \"\"\"Convert a list of tweet ids to a list of its corresponding public_metrics in data_df\n",
    "    Sort by tweets original create time\"\"\"\n",
    "    if type(list_of_id) is not list:\n",
    "        # if input is a single id convert type\n",
    "        list_of_id = [list_of_id]\n",
    "    # Select dataframe based on a list of ids\n",
    "    selected_df = data_df[data_df['id'].astype(str).isin(list_of_id)]\n",
    "    # Sort by their created time\n",
    "    sorted_df = selected_df.sort_values(by = [\"created_at\"])\n",
    "    # Select metric field only\n",
    "    metric_list = sorted_df[\"public_metrics\"].to_list()\n",
    "    return metric_list\n",
    "\n",
    "def remove_URL(original):\n",
    "    \"\"\"Remove url link in the text\"\"\"\n",
    "    result = re.sub(r\"http\\S+\", \"\", original)\n",
    "    result = re.sub(r\"www.\\S+\", \"\", result)\n",
    "    result = re.sub(r\"wasap.my+\", \"\", result)\n",
    "    return result\n",
    "\n",
    "def join_data_id_label_v2(LABEL_PATH, ID_PATH, DATA_PATH):\n",
    "    # Process Labels\n",
    "    if LABEL_PATH:\n",
    "        # 1: Rumour\n",
    "        # 0: NonRumour\n",
    "        with open(LABEL_PATH, \"r\") as f:\n",
    "            y_label = f.read().strip().split(\"\\n\") # remove next line\n",
    "        y_label = pd.DataFrame(y_label, columns = [\"label\"])\n",
    "        y_label[y_label[\"label\"]==\"rumour\"] = 1\n",
    "        y_label[y_label[\"label\"]==\"nonrumour\"] = 0\n",
    "\n",
    "    ## Get Dataframe Id, with first id as source Id, and values as replies, not using dict since we have duplicated keys\n",
    "    total_id_list = []\n",
    "    with open(ID_PATH, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(',') # remove next line\n",
    "            source_id = line[0]\n",
    "            if len(line) > 1:\n",
    "                # if we have replies id\n",
    "                replies_id = line[1:]\n",
    "            else:\n",
    "                replies_id = []\n",
    "            row = [source_id, replies_id]\n",
    "            total_id_list.append(row)\n",
    "    len(total_id_list)\n",
    "    \n",
    "    ## Create a dataframe containing a list of replies\n",
    "    source_df = pd.DataFrame(total_id_list, columns = ['source_id', 'replies_id'])\n",
    "    data_df = pd.read_json(DATA_PATH)\n",
    "    source_df[\"reply_text_list\"] = source_df[\"replies_id\"].apply(convert_replies_id_to_sorted_text, data_df = data_df)\n",
    "    source_df[\"source_text\"]     = source_df[\"source_id\"].apply(convert_replies_id_to_sorted_text, data_df = data_df)\n",
    "    source_df[\"metrics_replies\"]         = source_df[\"replies_id\"].apply(convert_replies_id_to_metrics, data_df = data_df)\n",
    "    source_df[\"metrics_source\"]  = source_df[\"source_id\"].apply(convert_replies_id_to_metrics, data_df = data_df)\n",
    "\n",
    "    if LABEL_PATH:\n",
    "      source_df[\"label\"] = y_label\n",
    "    return source_df\n",
    "\n",
    "def meta_preprocess(IDS, DATA, LABELS=False):\n",
    "    \"\"\"Function to combine all the preprocessing steps\"\"\"\n",
    "    data = join_data_id_label_v2(LABELS, IDS, DATA)\n",
    "    ## 1. Only keep english tweets as most of them are in english\n",
    "    # Use only text data and remove URLs\n",
    "    data[\"source\"] = data[\"source_text\"].apply(\" \".join).apply(remove_URL) \n",
    "    data[\"replies\"] = data[\"reply_text_list\"].apply(\" \".join).apply(remove_URL)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f522325",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./full_data/data_storage/full_train.json\"\n",
    "Y_TRAIN_ID_PATH = \"./id_data/train.label.txt\"\n",
    "X_TRAIN_ID_PATH = \"./id_data/train.data.txt\"   # train\n",
    "data_train = meta_preprocess(X_TRAIN_ID_PATH, TRAIN_DATA_PATH, LABELS=Y_DEV_ID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "50620ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_DATA_PATH = \"./full_data/data_storage/full_dev.json\"\n",
    "Y_DEV_ID_PATH = \"./id_data/dev.label.txt\"\n",
    "X_DEV_ID_PATH = \"./id_data/dev.data.txt\"   # dev\n",
    "data_dev = meta_preprocess(X_DEV_ID_PATH, DEV_DATA_PATH, LABELS=Y_DEV_ID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f4fa3a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>possibly_sensitive_appealable</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-17 17:53:32+00:00</td>\n",
       "      <td>1218229883484155913</td>\n",
       "      <td>1218229883484155904</td>\n",
       "      <td>Q: What is a #coronavirus?\\n\\nA: Coronaviruses...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-17 18:10:42+00:00</td>\n",
       "      <td>1218234203361480704</td>\n",
       "      <td>1218234203361480704</td>\n",
       "      <td>Q: What is a novel #coronavirus?\\n\\nA: A novel...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.218230e+18</td>\n",
       "      <td>1.218230e+18</td>\n",
       "      <td>14499829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17 19:14:05+00:00</td>\n",
       "      <td>1218250153901076482</td>\n",
       "      <td>1218250153901076480</td>\n",
       "      <td>@WHOThailand @WHOKobe @WHOSEARO @WHOWPRO Q: Wh...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.218234e+18</td>\n",
       "      <td>1.218234e+18</td>\n",
       "      <td>14499829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-17 19:36:05+00:00</td>\n",
       "      <td>1218255692831903744</td>\n",
       "      <td>1218255692831903744</td>\n",
       "      <td>Q: Is there a treatment for a novel #coronavir...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.218250e+18</td>\n",
       "      <td>1.218250e+18</td>\n",
       "      <td>14499829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-17 20:30:40+00:00</td>\n",
       "      <td>1218269428166602753</td>\n",
       "      <td>1218269428166602752</td>\n",
       "      <td>Q: What can I do to protect myself from #coron...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.218256e+18</td>\n",
       "      <td>1.218256e+18</td>\n",
       "      <td>14499829.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>{'media': [{'id': 1218269422605012994, 'id_str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14499829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>2015-12-27 17:24:29+00:00</td>\n",
       "      <td>681163757855338496</td>\n",
       "      <td>681163757855338496</td>\n",
       "      <td>@TMZ @Chillinlaidback @katyperry you're the be...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>16331010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>8729442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>2015-12-27 17:52:09+00:00</td>\n",
       "      <td>681170718843899904</td>\n",
       "      <td>681170718843899904</td>\n",
       "      <td>@TMZ This story makes my heart smile. Great jo...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>16331010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4218264718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>2015-12-27 22:42:47+00:00</td>\n",
       "      <td>681243858156556289</td>\n",
       "      <td>681243858156556288</td>\n",
       "      <td>@TMZ Katy s great !!!! Taylor swift would of m...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>6.811478e+17</td>\n",
       "      <td>16331010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>141024650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>2016-01-08 23:55:40+00:00</td>\n",
       "      <td>685610853979164672</td>\n",
       "      <td>685610853979164672</td>\n",
       "      <td>@EndlessPain89 @ComplexMag is that so?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>6.519601e+17</td>\n",
       "      <td>6.519601e+17</td>\n",
       "      <td>395645110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1538152554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>2011-06-13 01:14:56+00:00</td>\n",
       "      <td>80080680482123777</td>\n",
       "      <td>80080680482123776</td>\n",
       "      <td>Seriously? Racist McDonald’s Sign Is Obviously...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Hootsuite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>972651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8159 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at                   id               id_str  \\\n",
       "0    2020-01-17 17:53:32+00:00  1218229883484155913  1218229883484155904   \n",
       "1    2020-01-17 18:10:42+00:00  1218234203361480704  1218234203361480704   \n",
       "2    2020-01-17 19:14:05+00:00  1218250153901076482  1218250153901076480   \n",
       "3    2020-01-17 19:36:05+00:00  1218255692831903744  1218255692831903744   \n",
       "4    2020-01-17 20:30:40+00:00  1218269428166602753  1218269428166602752   \n",
       "...                        ...                  ...                  ...   \n",
       "8154 2015-12-27 17:24:29+00:00   681163757855338496   681163757855338496   \n",
       "8155 2015-12-27 17:52:09+00:00   681170718843899904   681170718843899904   \n",
       "8156 2015-12-27 22:42:47+00:00   681243858156556289   681243858156556288   \n",
       "8157 2016-01-08 23:55:40+00:00   685610853979164672   685610853979164672   \n",
       "8158 2011-06-13 01:14:56+00:00    80080680482123777    80080680482123776   \n",
       "\n",
       "                                                   text  truncated  \\\n",
       "0     Q: What is a #coronavirus?\\n\\nA: Coronaviruses...       True   \n",
       "1     Q: What is a novel #coronavirus?\\n\\nA: A novel...       True   \n",
       "2     @WHOThailand @WHOKobe @WHOSEARO @WHOWPRO Q: Wh...       True   \n",
       "3     Q: Is there a treatment for a novel #coronavir...       True   \n",
       "4     Q: What can I do to protect myself from #coron...      False   \n",
       "...                                                 ...        ...   \n",
       "8154  @TMZ @Chillinlaidback @katyperry you're the be...      False   \n",
       "8155  @TMZ This story makes my heart smile. Great jo...      False   \n",
       "8156  @TMZ Katy s great !!!! Taylor swift would of m...      False   \n",
       "8157             @EndlessPain89 @ComplexMag is that so?      False   \n",
       "8158  Seriously? Racist McDonald’s Sign Is Obviously...      False   \n",
       "\n",
       "                                               entities               source  \\\n",
       "0     {'hashtags': [{'text': 'coronavirus', 'indices...      Twitter Web App   \n",
       "1     {'hashtags': [{'text': 'coronavirus', 'indices...      Twitter Web App   \n",
       "2     {'hashtags': [{'text': 'coronavirus', 'indices...      Twitter Web App   \n",
       "3     {'hashtags': [{'text': 'coronavirus', 'indices...   Twitter for iPhone   \n",
       "4     {'hashtags': [{'text': 'coronavirus', 'indices...   Twitter for iPhone   \n",
       "...                                                 ...                  ...   \n",
       "8154  {'hashtags': [], 'symbols': [], 'user_mentions...  Twitter for Android   \n",
       "8155  {'hashtags': [], 'symbols': [], 'user_mentions...   Twitter Web Client   \n",
       "8156  {'hashtags': [], 'symbols': [], 'user_mentions...     Twitter for iPad   \n",
       "8157  {'hashtags': [], 'symbols': [], 'user_mentions...   Twitter for iPhone   \n",
       "8158  {'hashtags': [], 'symbols': [], 'user_mentions...            Hootsuite   \n",
       "\n",
       "      in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "0                       NaN                        NaN                  NaN   \n",
       "1              1.218230e+18               1.218230e+18           14499829.0   \n",
       "2              1.218234e+18               1.218234e+18           14499829.0   \n",
       "3              1.218250e+18               1.218250e+18           14499829.0   \n",
       "4              1.218256e+18               1.218256e+18           14499829.0   \n",
       "...                     ...                        ...                  ...   \n",
       "8154           6.811478e+17               6.811478e+17           16331010.0   \n",
       "8155           6.811478e+17               6.811478e+17           16331010.0   \n",
       "8156           6.811478e+17               6.811478e+17           16331010.0   \n",
       "8157           6.519601e+17               6.519601e+17          395645110.0   \n",
       "8158                    NaN                        NaN                  NaN   \n",
       "\n",
       "      ...  retweeted possibly_sensitive lang  \\\n",
       "0     ...      False                0.0   en   \n",
       "1     ...      False                0.0   en   \n",
       "2     ...      False                0.0   en   \n",
       "3     ...      False                0.0   en   \n",
       "4     ...      False                0.0   en   \n",
       "...   ...        ...                ...  ...   \n",
       "8154  ...      False                NaN   en   \n",
       "8155  ...      False                NaN   en   \n",
       "8156  ...      False                NaN   en   \n",
       "8157  ...      False                NaN   en   \n",
       "8158  ...      False                NaN   en   \n",
       "\n",
       "                                      extended_entities quoted_status_id  \\\n",
       "0                                                  None              NaN   \n",
       "1                                                  None              NaN   \n",
       "2                                                  None              NaN   \n",
       "3                                                  None              NaN   \n",
       "4     {'media': [{'id': 1218269422605012994, 'id_str...              NaN   \n",
       "...                                                 ...              ...   \n",
       "8154                                               None              NaN   \n",
       "8155                                               None              NaN   \n",
       "8156                                               None              NaN   \n",
       "8157                                               None              NaN   \n",
       "8158                                               None              NaN   \n",
       "\n",
       "     quoted_status_id_str  quoted_status  possibly_sensitive_appealable  \\\n",
       "0                     NaN           None                            NaN   \n",
       "1                     NaN           None                            NaN   \n",
       "2                     NaN           None                            NaN   \n",
       "3                     NaN           None                            NaN   \n",
       "4                     NaN           None                            NaN   \n",
       "...                   ...            ...                            ...   \n",
       "8154                  NaN           None                            NaN   \n",
       "8155                  NaN           None                            NaN   \n",
       "8156                  NaN           None                            NaN   \n",
       "8157                  NaN           None                            NaN   \n",
       "8158                  NaN           None                            NaN   \n",
       "\n",
       "      withheld_in_countries   author_id  \n",
       "0                      None    14499829  \n",
       "1                      None    14499829  \n",
       "2                      None    14499829  \n",
       "3                      None    14499829  \n",
       "4                      None    14499829  \n",
       "...                     ...         ...  \n",
       "8154                   None     8729442  \n",
       "8155                   None  4218264718  \n",
       "8156                   None   141024650  \n",
       "8157                   None  1538152554  \n",
       "8158                   None      972651  \n",
       "\n",
       "[8159 rows x 31 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATA_PATH = \"./full_data/data_storage/test_data.json\"\n",
    "X_TEST_ID_PATH = \"./id_data/test.data.txt\"   # test\n",
    "data_test = pd.read_json(TEST_DATA_PATH)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b70c2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [0, 1, 0, 0]\n",
       "1        [184, 35, 44, 0]\n",
       "2            [1, 1, 4, 1]\n",
       "3         [121, 5, 23, 0]\n",
       "4            [1, 0, 6, 0]\n",
       "              ...        \n",
       "1890      [76, 30, 56, 0]\n",
       "1891    [108, 36, 148, 0]\n",
       "1892      [176, 9, 63, 0]\n",
       "1893                   []\n",
       "1894         [0, 3, 0, 0]\n",
       "Name: metrics_source, Length: 1895, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_metrics(metric_dicts):\n",
    "    metrics = []\n",
    "    for metric_dict in metric_dicts:\n",
    "        metrics += metric_dict.values()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d6116d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"metrics\"] = data_train[\"metrics_source\"].apply(get_metrics)\n",
    "data_train = data_train.where(cond).dropna()\n",
    "data_train_meta = data_train[[\"metrics\", \"label\"]]\n",
    "# Get only the instances that have a metrics_source that's nonempty\n",
    "cond = data_train[\"metrics\"].apply(lambda l: len(l)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66afabef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = data_train_meta[\"metrics\"], data_train_meta[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "y_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b52d82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train.values.tolist(), y_train.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c0e0df51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083067092651757"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test.values.tolist(), y_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392db401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
