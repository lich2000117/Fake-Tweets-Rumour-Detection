{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79126c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6ef0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_TWITTER_PATH = \"./full_data/data_storage/full_train_source_only.json\"\n",
    "FULL_TWITTER_PATH = \"./full_data/data_storage/full_train.json\"\n",
    "Y_TRAIN_PATH = \"./id_data/train.label.txt\"\n",
    "X_TRAIN_PATH = \"./id_data/train.data.txt\"   # train\n",
    "SOURCE_STORY_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76cbf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data_id_label(LABEL_PATH, ID_PATH, DATA_PATH, dropna_on_column=\"text\", SOURCE_STORY_ONLY=True):\n",
    "    \"\"\"A function that joins data and id and their labels, return a dataframe that trims off twitter we don't have data\"\"\"\n",
    "    # Process Labels\n",
    "    if LABEL_PATH:\n",
    "        # 1: Rumour\n",
    "        # 0: NonRumour\n",
    "        with open(LABEL_PATH, \"r\") as f:\n",
    "            y_label = f.read().strip().split(\"\\n\") # remove next line\n",
    "        y_label = pd.DataFrame(y_label, columns = [\"label\"])\n",
    "        y_label[y_label[\"label\"]==\"rumour\"] = 1\n",
    "        y_label[y_label[\"label\"]==\"nonrumour\"] = 0\n",
    "    \n",
    "    \n",
    "    ## Get Dataframe Id\n",
    "    total_id_list = []\n",
    "    with open(ID_PATH, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip() # remove next line\n",
    "            if SOURCE_STORY_ONLY:\n",
    "                line = line.split(',')[0] # split into list\\\n",
    "            else:\n",
    "                line = line.split(',')\n",
    "            total_id_list.append(line)\n",
    "            \n",
    "    if not SOURCE_STORY_ONLY:\n",
    "        total_id_list = [item for sublist in total_id_list for item in sublist] # Flat into a single list\n",
    "    total_id_list = total_id_list\n",
    "    id_df = pd.DataFrame(total_id_list, columns=[\"id\"])\n",
    "    id_df[\"id\"] = id_df[\"id\"].astype(str)\n",
    "    # join their labels\n",
    "    if LABEL_PATH:\n",
    "    # if we are processing testing data, don't add label\n",
    "        id_df[\"label\"] = y_label[\"label\"]\n",
    "    \n",
    "    ## Get Twitter Data\n",
    "    # Read Source Data\n",
    "    data_df = pd.read_json(DATA_PATH)\n",
    "    #source_df = pd.concat([source_df, y_train], axis=1)\n",
    "    data_df[\"id\"] = data_df[\"id\"].astype(str)\n",
    "    \n",
    "    ## Join the data file and IDs we got \n",
    "    ## Drop rows we don't have data on\n",
    "    combined_df = id_df.join(data_df.set_index('id'), on='id')\n",
    "    if dropna_on_column:\n",
    "        combined_df = combined_df.dropna(subset=['text', 'author_id']).reset_index(drop=True)\n",
    "    combined_df.reindex(total_id_list) # make sure we have the right order\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15ff701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_URL(original):\n",
    "    \"\"\"Remove url link in the text\"\"\"\n",
    "    result = re.sub(r\"http\\S+\", \"\", original)\n",
    "    result = re.sub(r\"www.\\S+\", \"\", result)\n",
    "    result = re.sub(r\"wasap.my+\", \"\", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cfae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/27084617/detect-strings-with-non-english-characters-in-python\n",
    "def isEnglish(s):\n",
    "    s = str(s)\n",
    "    \"\"\"Check if a string is english\"\"\"\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776b035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_processing(input_str):\n",
    "    \"\"\"A function takes a input text string and output a list of preprocessed words\n",
    "        1. Remove URL\n",
    "        2. StopWords Removal\n",
    "        3. Remove Non-English Words\n",
    "        4. Remove Numeric Value\n",
    "        5. Lemmatize\n",
    "    \n",
    "    \"\"\"\n",
    "    list_words = []\n",
    "    # Remove URL\n",
    "    input_str = Remove_URL(input_str)\n",
    "    for word in re.sub(r'[^\\w\\s]','', input_str).split():\n",
    "        # Remove Numeric Value, Non-English words and Stop words\n",
    "        if (word.isalpha()) and (isEnglish(word)) and (word not in stopwords.words('english')):\n",
    "            # Remove Links in the text\n",
    "            # Lemmatize words\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # Add to List\n",
    "            list_words.append(word)\n",
    "    return list_words\n",
    "\n",
    "#filtered_words = [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d142e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expand list of words into bag-of-words array\n",
    "def get_bag_of_words(df_column):\n",
    "    \"\"\"Expand list of words into bag-of-words array, return the dataframe.\"\"\"\n",
    "    return pd.get_dummies(df_column.apply(pd.Series).stack()).groupby(level=0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1d7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = join_data_id_label(Y_TRAIN_PATH, X_TRAIN_PATH, SOURCE_TWITTER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec0f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang\n",
      "en      1547\n",
      "und        4\n",
      "es         2\n",
      "in         2\n",
      "ro         2\n",
      "hu         1\n",
      "it         1\n",
      "ja         1\n",
      "ru         1\n",
      "zh         1\n",
      "dtype: int64\n",
      "============\n",
      "withheld\n",
      "False       1551\n",
      "True          11\n",
      "dtype: int64\n",
      "============\n",
      "reply_settings\n",
      "everyone          1562\n",
      "dtype: int64\n",
      "============\n",
      "source                 \n",
      "Twitter Web App            406\n",
      "Twitter for Android        291\n",
      "Twitter for iPhone         286\n",
      "TweetDeck                  165\n",
      "Twitter Web Client         110\n",
      "                          ... \n",
      "The New York Times           1\n",
      "TheLatestIs                  1\n",
      "TweetCaster for Android      1\n",
      "Sendible                     1\n",
      "AOL Blogsmith                1\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train[[\"lang\"]].value_counts())\n",
    "print(\"============\")\n",
    "print(X_train[[\"withheld\"]].value_counts())\n",
    "print(\"============\")\n",
    "print(X_train[[\"reply_settings\"]].value_counts())\n",
    "print(\"============\")\n",
    "print(X_train[[\"source\"]].value_counts())\n",
    "\n",
    "## Only keep English! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef9fe0",
   "metadata": {},
   "source": [
    "###  Standard Scaler to do PCA to do dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a23a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9564301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize, why? it needs to do to use PCA, also, it needs to have variance of 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pca = PCA(n_components=200, random_state=5)\n",
    "\n",
    "pca600 = PCA(n_components=1000, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48634df6",
   "metadata": {},
   "source": [
    "# Only Use Text Data\n",
    "other fields including author information, entities, public matrix, and source not used!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d937f53",
   "metadata": {},
   "source": [
    "### Process Training Data use above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d3c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to normalize json field in the data? \n",
    "\n",
    "## NOT YET USED!\n",
    "#pd.json_normalize(X_train['public_metrics']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2761e4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>source</th>\n",
       "      <th>withheld</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>entities</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250219300389974016</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-15 00:28:03+00:00</td>\n",
       "      <td>3.123627e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>{'urls': [{'start': 96, 'end': 119, 'url': 'ht...</td>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554886875303780352</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-13 06:25:15+00:00</td>\n",
       "      <td>1.634397e+07</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 184, 'reply_count': 35, 'lik...</td>\n",
       "      <td>{'urls': [{'start': 62, 'end': 84, 'url': 'htt...</td>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237901309011021825</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-12 00:40:45+00:00</td>\n",
       "      <td>2.850483e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>{'urls': [{'start': 186, 'end': 209, 'url': 'h...</td>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524958128392376320</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 16:19:05+00:00</td>\n",
       "      <td>3.108351e+06</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>SocialFlow</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 121, 'reply_count': 5, 'like...</td>\n",
       "      <td>{'annotations': [{'start': 0, 'end': 5, 'proba...</td>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239295488677085185</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-15 21:00:44+00:00</td>\n",
       "      <td>1.053802e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>None</td>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>1237545128828342277</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-11 01:05:25+00:00</td>\n",
       "      <td>8.225705e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>{'annotations': [{'start': 58, 'end': 62, 'pro...</td>\n",
       "      <td>4. It cannot be transmitted through goods manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>671181758692507648</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-30 04:19:35+00:00</td>\n",
       "      <td>4.876003e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Mobile Web</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 76, 'reply_count': 30, 'like...</td>\n",
       "      <td>{'urls': [{'start': 101, 'end': 124, 'url': 'h...</td>\n",
       "      <td>Desperate Ted Cruz Claims Planned Parenthood S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>672513234419638273</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-03 20:30:24+00:00</td>\n",
       "      <td>2.878549e+07</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 108, 'reply_count': 36, 'lik...</td>\n",
       "      <td>{'annotations': [{'start': 45, 'end': 49, 'pro...</td>\n",
       "      <td>\"Thoughts and prayers are not enough.\" Pres. O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>553508098825261056</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-09 11:06:29+00:00</td>\n",
       "      <td>1.417332e+07</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Hootsuite</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 176, 'reply_count': 9, 'like...</td>\n",
       "      <td>{'urls': [{'start': 94, 'end': 116, 'url': 'ht...</td>\n",
       "      <td>Police have surrounded this building where the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1241082793737818113</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-20 19:22:50+00:00</td>\n",
       "      <td>7.310695e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 3, 'like_c...</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 13, 'usernam...</td>\n",
       "      <td>@lynneSimpkin I can help! üë©‚Äçüè´\\n9am: Socialism ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1562 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id label                created_at     author_id lang  \\\n",
       "0     1250219300389974016     0 2020-04-15 00:28:03+00:00  3.123627e+08   en   \n",
       "1      554886875303780352     1 2015-01-13 06:25:15+00:00  1.634397e+07   en   \n",
       "2     1237901309011021825     0 2020-03-12 00:40:45+00:00  2.850483e+08   en   \n",
       "3      524958128392376320     0 2014-10-22 16:19:05+00:00  3.108351e+06   en   \n",
       "4     1239295488677085185     0 2020-03-15 21:00:44+00:00  1.053802e+18   en   \n",
       "...                   ...   ...                       ...           ...  ...   \n",
       "1557  1237545128828342277     0 2020-03-11 01:05:25+00:00  8.225705e+08   en   \n",
       "1558   671181758692507648     1 2015-11-30 04:19:35+00:00  4.876003e+08   en   \n",
       "1559   672513234419638273     1 2015-12-03 20:30:24+00:00  2.878549e+07   en   \n",
       "1560   553508098825261056     0 2015-01-09 11:06:29+00:00  1.417332e+07   en   \n",
       "1561  1241082793737818113     0 2020-03-20 19:22:50+00:00  7.310695e+08   en   \n",
       "\n",
       "     reply_settings               source withheld  \\\n",
       "0          everyone      Twitter Web App    False   \n",
       "1          everyone            TweetDeck    False   \n",
       "2          everyone      Twitter Web App    False   \n",
       "3          everyone           SocialFlow    False   \n",
       "4          everyone   Twitter for iPhone    False   \n",
       "...             ...                  ...      ...   \n",
       "1557       everyone      Twitter Web App    False   \n",
       "1558       everyone           Mobile Web    False   \n",
       "1559       everyone   Twitter Web Client    False   \n",
       "1560       everyone            Hootsuite    False   \n",
       "1561       everyone  Twitter for Android    False   \n",
       "\n",
       "                                         public_metrics  \\\n",
       "0     {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "1     {'retweet_count': 184, 'reply_count': 35, 'lik...   \n",
       "2     {'retweet_count': 1, 'reply_count': 1, 'like_c...   \n",
       "3     {'retweet_count': 121, 'reply_count': 5, 'like...   \n",
       "4     {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "...                                                 ...   \n",
       "1557  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "1558  {'retweet_count': 76, 'reply_count': 30, 'like...   \n",
       "1559  {'retweet_count': 108, 'reply_count': 36, 'lik...   \n",
       "1560  {'retweet_count': 176, 'reply_count': 9, 'like...   \n",
       "1561  {'retweet_count': 0, 'reply_count': 3, 'like_c...   \n",
       "\n",
       "                                               entities  \\\n",
       "0     {'urls': [{'start': 96, 'end': 119, 'url': 'ht...   \n",
       "1     {'urls': [{'start': 62, 'end': 84, 'url': 'htt...   \n",
       "2     {'urls': [{'start': 186, 'end': 209, 'url': 'h...   \n",
       "3     {'annotations': [{'start': 0, 'end': 5, 'proba...   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1557  {'annotations': [{'start': 58, 'end': 62, 'pro...   \n",
       "1558  {'urls': [{'start': 101, 'end': 124, 'url': 'h...   \n",
       "1559  {'annotations': [{'start': 45, 'end': 49, 'pro...   \n",
       "1560  {'urls': [{'start': 94, 'end': 116, 'url': 'ht...   \n",
       "1561  {'mentions': [{'start': 0, 'end': 13, 'usernam...   \n",
       "\n",
       "                                                   text  \n",
       "0     5. Can regularly rinsing your nose with saline...  \n",
       "1     French police chief killed himself after #Char...  \n",
       "2     Coronavirus disease (COVID-19) advice for the ...  \n",
       "3     Ottawa police confirm that there were multiple...  \n",
       "4     if the primary focus of a government isn't to ...  \n",
       "...                                                 ...  \n",
       "1557  4. It cannot be transmitted through goods manu...  \n",
       "1558  Desperate Ted Cruz Claims Planned Parenthood S...  \n",
       "1559  \"Thoughts and prayers are not enough.\" Pres. O...  \n",
       "1560  Police have surrounded this building where the...  \n",
       "1561  @lynneSimpkin I can help! üë©‚Äçüè´\\n9am: Socialism ...  \n",
       "\n",
       "[1562 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "X_train = join_data_id_label(Y_TRAIN_PATH, X_TRAIN_PATH, SOURCE_TWITTER_PATH)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07ceb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250219300389974016</td>\n",
       "      <td>en</td>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Can, regularly, rinsing, nose, saline, help, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554886875303780352</td>\n",
       "      <td>en</td>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "      <td>1</td>\n",
       "      <td>[French, police, chief, killed, CharlieHebdo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237901309011021825</td>\n",
       "      <td>en</td>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Coronavirus, disease, advice, public, Should,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524958128392376320</td>\n",
       "      <td>en</td>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ottawa, police, confirm, multiple, suspect, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239295488677085185</td>\n",
       "      <td>en</td>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[primary, focus, government, isnt, alleviate, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang  \\\n",
       "0  1250219300389974016   en   \n",
       "1   554886875303780352   en   \n",
       "2  1237901309011021825   en   \n",
       "3   524958128392376320   en   \n",
       "4  1239295488677085185   en   \n",
       "\n",
       "                                                text label  \\\n",
       "0  5. Can regularly rinsing your nose with saline...     0   \n",
       "1  French police chief killed himself after #Char...     1   \n",
       "2  Coronavirus disease (COVID-19) advice for the ...     0   \n",
       "3  Ottawa police confirm that there were multiple...     0   \n",
       "4  if the primary focus of a government isn't to ...     0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [Can, regularly, rinsing, nose, saline, help, ...  \n",
       "1  [French, police, chief, killed, CharlieHebdo, ...  \n",
       "2  [Coronavirus, disease, advice, public, Should,...  \n",
       "3  [Ottawa, police, confirm, multiple, suspect, s...  \n",
       "4  [primary, focus, government, isnt, alleviate, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## 1. Only keep english tweets as most of them are in english\n",
    "## 2. Based on the values count, drop irrelevant features \"reply_settings\" too\n",
    "X_train = X_train[X_train.lang==\"en\"].reset_index(drop=True)\n",
    "X_train = X_train[['id','lang', 'text','label']]\n",
    "# Use only text data and tokenize\n",
    "X_train[\"clean_text\"] = X_train[\"text\"].apply(text_processing)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66863aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCNews</th>\n",
       "      <th>ABOUT</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACCORDING</th>\n",
       "      <th>ACCURATE</th>\n",
       "      <th>ACTED</th>\n",
       "      <th>AFFECT</th>\n",
       "      <th>...</th>\n",
       "      <th>youd</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yourbabazg</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zaelefty</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwinst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  AB  ABC  ABCNews  ABOUT  AC  ACCORDING  ACCURATE  ACTED  AFFECT  ...  \\\n",
       "0  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "1  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "2  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "3  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "4  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "\n",
       "   youd  young  younger  yourbabazg  youre  youve  zaelefty  zero  zoom  \\\n",
       "0     0      0        0           0      0      0         0     0     0   \n",
       "1     0      0        0           0      0      0         0     0     0   \n",
       "2     0      0        0           0      0      0         0     0     0   \n",
       "3     0      0        0           0      0      0         0     0     0   \n",
       "4     0      0        0           0      0      0         0     0     0   \n",
       "\n",
       "   zwinst  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 5681 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "X_train = join_data_id_label(Y_TRAIN_PATH, X_TRAIN_PATH, SOURCE_TWITTER_PATH)\n",
    "\n",
    "\n",
    "## 1. Only keep english tweets as most of them are in english\n",
    "## 2. Based on the values count, drop irrelevant features \"reply_settings\" too\n",
    "X_train = X_train[X_train.lang==\"en\"].reset_index(drop=True)\n",
    "X_train = X_train[['id','lang', 'text','label']]\n",
    "# Use only text data and tokenize\n",
    "X_train[\"clean_text\"] = X_train[\"text\"].apply(text_processing)\n",
    "# Get BOF dataframe\n",
    "X_train_BOW = get_bag_of_words(X_train[\"clean_text\"])\n",
    "X_train_BOW.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e10672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train test data\n",
    "y_train = X_train[\"label\"].astype(int)\n",
    "X_train = X_train_BOW\n",
    "\n",
    "assert(len(X_train) == len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec0f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform using Train Data\n",
    "\n",
    "train_columns = X_train.columns\n",
    "\n",
    "# StandardScaler\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=train_columns)\n",
    "\n",
    "# PCA\n",
    "X_train_scaled_reduced = pd.DataFrame(pca.fit_transform(X_train_scaled))\n",
    "\n",
    "X_train_scaled_reduced_pca600 = pd.DataFrame(pca600.fit_transform(X_train_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7b561",
   "metadata": {},
   "source": [
    "### Dev Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e796be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training_columns_only(test_BOW_df, train_column, default_value=0):\n",
    "    \"\"\"Take a BOW dataframe and keep only the words from training dataframe, return a dataframe\"\"\"\n",
    "    return test_BOW_df.reindex(columns = train_columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c269cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SOURCE_TWITTER_PATH = \"./full_data/data_storage/full_dev_source_only.json\"\n",
    "#DEV_FULL_TWITTER_PATH = \"./full_data/data_storage/full_dev.json\"\n",
    "Y_DEV_PATH = \"./id_data/dev.label.txt\"\n",
    "X_DEV_PATH = \"./id_data/dev.data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c666e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCNews</th>\n",
       "      <th>ABOUT</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACCORDING</th>\n",
       "      <th>ACCURATE</th>\n",
       "      <th>ACTED</th>\n",
       "      <th>AFFECT</th>\n",
       "      <th>...</th>\n",
       "      <th>youd</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yourbabazg</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zaelefty</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwinst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  AB  ABC  ABCNews  ABOUT  AC  ACCORDING  ACCURATE  ACTED  AFFECT  ...  \\\n",
       "0  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "1  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "2  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "3  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "4  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "\n",
       "   youd  young  younger  yourbabazg  youre  youve  zaelefty  zero  zoom  \\\n",
       "0     0      0        0           0      0      0         0     0     0   \n",
       "1     0      0        0           0      0      0         0     0     0   \n",
       "2     0      0        0           0      0      0         0     0     0   \n",
       "3     0      0        0           0      0      0         0     0     0   \n",
       "4     0      0        0           0      0      0         0     0     0   \n",
       "\n",
       "   zwinst  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 5681 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "X_dev = join_data_id_label(Y_DEV_PATH, X_DEV_PATH, DEV_SOURCE_TWITTER_PATH)\n",
    "\n",
    "\n",
    "## 1. Only keep english tweets as most of them are in english\n",
    "## 2. Based on the values count, drop irrelevant features \"reply_settings\" too\n",
    "X_dev = X_dev[X_dev.lang==\"en\"].reset_index(drop=True)\n",
    "X_dev = X_dev[['id','lang', 'text','label']]\n",
    "# Use only text data and tokenize\n",
    "X_dev[\"clean_text\"] = X_dev[\"text\"].apply(text_processing)\n",
    "# Get BOF dataframe\n",
    "X_dev_BOW = get_bag_of_words(X_dev[\"clean_text\"])\n",
    "\n",
    "## Keep training columns only\n",
    "X_dev_BOW = keep_training_columns_only(X_dev_BOW, train_columns, default_value=0)\n",
    "\n",
    "X_dev_BOW.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2edb8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train test data\n",
    "y_dev = X_dev[\"label\"].astype(int)\n",
    "X_dev = X_dev_BOW\n",
    "\n",
    "assert(len(X_dev) == len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f1d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform using Trained Transformer\n",
    "\n",
    "# StandardScaler\n",
    "X_dev_scaled = pd.DataFrame(scaler.transform(X_dev), columns=train_columns)\n",
    "\n",
    "# PCA\n",
    "X_dev_scaled_reduced = pd.DataFrame(pca.transform(X_dev_scaled))\n",
    "X_dev_scaled_reduced_pca600 = pd.DataFrame(pca600.transform(X_dev_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6eff8",
   "metadata": {},
   "source": [
    "# ML Models Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43a812",
   "metadata": {},
   "source": [
    "## Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc73f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3402e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9993535875888817\n",
      "Test Score:  0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier() # early_stopping=True\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "Train_Score = mlp_clf.score(X_train_scaled, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = mlp_clf.score(X_dev_scaled, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89957186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.9172932330827067\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_scaled, y_train)  # X_train_scaled_reduced for PCA\n",
    "\n",
    "Train_Score = lr_clf.score(X_train_scaled, y_train)  # X_train_scaled_reduced for PCA\n",
    "Test_Score = lr_clf.score(X_dev_scaled, y_dev)   # X_dev_scaled_reduced for PCA\n",
    "\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd5aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9883645765998708\n",
      "Test Score:  0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "Train_Score = svm_clf.score(X_train_scaled, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = svm_clf.score(X_dev_scaled, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b0cf50",
   "metadata": {},
   "source": [
    "## PCA = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b302206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.9022556390977443\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier() # early_stopping=True\n",
    "mlp_clf.fit(X_train_scaled_reduced, y_train) # X_train_scaled_reduced for PCA\n",
    "\n",
    "Train_Score = mlp_clf.score(X_train_scaled_reduced, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = mlp_clf.score(X_dev_scaled_reduced, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71a87247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9088558500323206\n",
      "Test Score:  0.8383458646616542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_scaled_reduced, y_train)  # X_train_scaled_reduced for PCA\n",
    "\n",
    "Train_Score = lr_clf.score(X_train_scaled_reduced, y_train)  # X_train_scaled_reduced for PCA\n",
    "Test_Score = lr_clf.score(X_dev_scaled_reduced, y_dev)   # X_dev_scaled_reduced for PCA\n",
    "\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a68df98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8784744667097608\n",
      "Test Score:  0.7988721804511278\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_scaled_reduced, y_train)\n",
    "\n",
    "Train_Score = svm_clf.score(X_train_scaled_reduced, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = svm_clf.score(X_dev_scaled_reduced, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a82c7d",
   "metadata": {},
   "source": [
    "## PCA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b0be661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.924812030075188\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier() # early_stopping=True\n",
    "mlp_clf.fit(X_train_scaled_reduced_pca600, y_train) # X_train_scaled_reduced for PCA\n",
    "\n",
    "Train_Score = mlp_clf.score(X_train_scaled_reduced_pca600, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = mlp_clf.score(X_dev_scaled_reduced_pca600, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c2c6d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.9323308270676691\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_scaled_reduced_pca600, y_train)  # X_train_scaled_reduced for PCA\n",
    "\n",
    "Train_Score = lr_clf.score(X_train_scaled_reduced_pca600, y_train)  # X_train_scaled_reduced for PCA\n",
    "Test_Score = lr_clf.score(X_dev_scaled_reduced_pca600, y_dev)   # X_dev_scaled_reduced for PCA\n",
    "\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b1c7a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9857789269553976\n",
      "Test Score:  0.8364661654135338\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_scaled_reduced_pca600, y_train)\n",
    "\n",
    "Train_Score = svm_clf.score(X_train_scaled_reduced_pca600, y_train) # X_train_scaled_reduced for PCA\n",
    "Test_Score = svm_clf.score(X_dev_scaled_reduced_pca600, y_dev) # X_dev_scaled_reduced for PCA\n",
    "print(\"Train Score: \", Train_Score)\n",
    "print(\"Test Score: \", Test_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a02872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6ddb5b9",
   "metadata": {},
   "source": [
    "## Test using model and save to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ce4451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ID_PATH = './id_data/test.data.txt'\n",
    "TEST_DATA_PATH = './id_data/tweet-objects/'\n",
    "TEST_DATA_JSON_PATH = './full_data/data_storage/test_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e0c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "json_files = [pos_json for pos_json in os.listdir(TEST_DATA_PATH) if pos_json.endswith('.json')]\n",
    "\n",
    "list_of_data = []\n",
    "for path in json_files:\n",
    "    with open(TEST_DATA_PATH + path, \"r\") as f:\n",
    "        list_of_data.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb2b2d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Read in Json and do some preprocessing \n",
    "test_df = pd.DataFrame(list_of_data)\n",
    "\n",
    "# Update source column\n",
    "test_df[\"source\"] = test_df[\"source\"].apply(lambda x: re.findall(r'>[^<]*<',x)[0][1:-1])\n",
    "# Get User ID\n",
    "test_df[\"author_id\"] = test_df[\"user\"].apply(lambda x: x[\"id\"])\n",
    "# Filter Non English text into empty string\n",
    "test_df.loc[test_df[\"lang\"]!=\"en\",\"text\"] = \"NA\"\n",
    "test_df.to_json(TEST_DATA_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e83d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCNews</th>\n",
       "      <th>ABOUT</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACCORDING</th>\n",
       "      <th>ACCURATE</th>\n",
       "      <th>ACTED</th>\n",
       "      <th>AFFECT</th>\n",
       "      <th>...</th>\n",
       "      <th>youd</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yourbabazg</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zaelefty</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwinst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  AB  ABC  ABCNews  ABOUT  AC  ACCORDING  ACCURATE  ACTED  AFFECT  ...  \\\n",
       "0  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "1  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "2  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "3  1   0    0        0      0   0          0         0      0       0  ...   \n",
       "4  0   0    0        0      0   0          0         0      0       0  ...   \n",
       "\n",
       "   youd  young  younger  yourbabazg  youre  youve  zaelefty  zero  zoom  \\\n",
       "0     0      0        0           0      0      0         0     0     0   \n",
       "1     0      0        0           0      0      0         0     0     0   \n",
       "2     0      0        0           0      0      0         0     0     0   \n",
       "3     0      0        0           0      0      0         0     0     0   \n",
       "4     0      0        0           0      0      0         0     0     0   \n",
       "\n",
       "   zwinst  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 5681 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = join_data_id_label(None, TEST_ID_PATH, TEST_DATA_JSON_PATH, dropna_on_column = None)\n",
    "X_test\n",
    "## 2. Based on the values count, drop irrelevant features \"reply_settings\" too\n",
    "X_test = X_test[['id','lang', 'text']]\n",
    "# Use only text data and tokenize\n",
    "X_test[\"clean_text\"] = X_test[\"text\"].apply(text_processing)\n",
    "# Get BOF dataframe\n",
    "X_test_BOW = get_bag_of_words(X_test[\"clean_text\"])\n",
    "\n",
    "## Keep training columns only\n",
    "X_test_BOW = keep_training_columns_only(X_test_BOW, train_columns, default_value=0)\n",
    "\n",
    "X_test_BOW.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc6cb85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.964157706093113"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_test_BOW.sum()/len(X_test_BOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "763a5616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.30639097744356"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_dev_BOW.sum()/len(X_dev_BOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ba11d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.915966386554574"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_train_BOW.sum()/len(X_train_BOW))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52e285",
   "metadata": {},
   "source": [
    "Too little information captured on test set! many words are not seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccdd480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_BOW\n",
    "## Transform using Trained Transformer\n",
    "\n",
    "# StandardScaler\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=train_columns)\n",
    "\n",
    "# PCA\n",
    "X_test_scaled_reduced = pd.DataFrame(pca.transform(X_test_scaled))\n",
    "X_test_scaled_reduced_pca600 = pd.DataFrame(pca600.transform(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa70a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the csv for prediction\n",
    "def generate_csv(pred, csv_name):\n",
    "    ids = pd.Index(range(len(pred)), name='Id')\n",
    "    predictions = pd.DataFrame(pred, index=ids)\n",
    "    predictions.columns = ['Predicted']\n",
    "    predictions.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5771bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_clf.predict(X_test_scaled_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ad2431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(y_pred)==558)\n",
    "generate_csv(y_pred, \"./test_pred/LR_PCA_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc2fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
